# Plan de Tests de Robustez - Pr√≥ximos Pasos

**Fecha:** 2025-12-20
**Estado actual:** Tests Error Handling completados ‚úÖ (170 tests totales, 166 passing, 4 skipped)
**√öltima actualizaci√≥n:** 2025-12-21
**Objetivo:** Fortalecer tests para Paso 2 (API REST) y preparar Paso 3 (AI Agents reales)

---

## üìä Estado Actual

### Tests Existentes (170 total)
- ‚úÖ **API:** 22 tests (endpoints b√°sicos, webhooks, health)
- ‚úÖ **MCP Mock:** 34 tests (auth, resources, tools, server HTTP) - 33 pass + 1 skip
- ‚úÖ **Backoffice:** 87 tests (executor, JWT, logging, MCP integration, protocols)
- ‚úÖ **Contracts:** 12 tests (MCP client, agent registry, config loader) ‚≠ê NUEVO
- ‚úÖ **Error Handling:** 15 tests (resilience, error cases) - 12 pass + 3 skip ‚≠ê NUEVO

### Coverage por Componente
| Componente | Tests | Coverage Estimado | Estado |
|------------|-------|-------------------|--------|
| AgentExecutor | 33 | ~85% | ‚úÖ Bueno |
| JWT Validation | 19 | ~95% | ‚úÖ Excelente |
| PII Redaction | 12 | ~90% | ‚úÖ Excelente |
| MCP Integration | 15 | ~70% | ‚ö†Ô∏è Mejorable |
| API Endpoints | 22 | ~60% | ‚ö†Ô∏è Mejorable |
| Error Handling | ~10 | ~50% | üî¥ Insuficiente |
| Webhooks | 12 | ~70% | ‚ö†Ô∏è Mejorable |

---

## üéØ Objetivos del Plan

### Objetivo 1: Completar Paso 2 (API REST) con Confianza
- Cubrir todos los casos edge de la API
- Validar comportamiento as√≠ncrono
- Asegurar manejo de errores robusto
- Preparar para carga en producci√≥n

### Objetivo 2: Preparar Paso 3 (Real AI Agents)
- Definir contratos entre AgentExecutor y agentes reales
- Tests de regresi√≥n para garantizar backward compatibility
- Validar que mocks y agentes reales son intercambiables

### Objetivo 3: Aumentar Confianza para Producci√≥n
- Tests de concurrencia
- Tests de resiliencia (retry, timeouts)
- Tests de seguridad adicionales
- Tests de performance

---

## üìã Categor√≠as de Tests Propuestos

### 1. Tests de Integraci√≥n End-to-End (E2E)

**Prioridad:** üî¥ ALTA
**Raz√≥n:** Validan el flujo completo API ‚Üí AgentExecutor ‚Üí MCP ‚Üí Respuesta
**Tests actuales:** 0
**Tests propuestos:** 8

#### Tests E2E Propuestos:

##### E2E-1: Flujo completo exitoso con agente mock
```python
@pytest.mark.integration
@pytest.mark.slow
async def test_e2e_api_to_mcp_successful_execution():
    """
    Test: API ‚Üí AgentExecutor ‚Üí MCP Mock ‚Üí Webhook exitoso

    Flujo:
    1. POST /api/v1/agent/execute con JWT v√°lido
    2. AgentExecutor valida JWT
    3. AgentExecutor crea MCP registry
    4. Agente mock ejecuta herramientas MCP
    5. Respuesta 202 Accepted con agent_run_id
    6. Webhook llamado con resultado SUCCESS
    7. Logs de auditor√≠a completos

    Validaciones:
    - Status 202
    - agent_run_id en respuesta
    - Webhook recibe resultado correcto
    - Log de auditor√≠a tiene todas las etapas
    - MCP tools fueron llamados correctamente
    """
```

##### E2E-2: Flujo completo con error de JWT
```python
async def test_e2e_api_jwt_error_propagation():
    """
    Test: Error de JWT se propaga correctamente a trav√©s del stack

    Flujo:
    1. POST /api/v1/agent/execute con JWT expirado
    2. AgentExecutor detecta token expirado
    3. Respuesta 401 Unauthorized
    4. Webhook NO es llamado
    5. Error loggeado en auditor√≠a

    Validaciones:
    - Status 401
    - C√≥digo de error AUTH_TOKEN_EXPIRED
    - Mensaje de error apropiado
    - No se intent√≥ conexi√≥n MCP
    - Log de auditor√≠a registra error
    """
```

##### E2E-3: Flujo completo con error de MCP
```python
async def test_e2e_api_mcp_connection_error():
    """
    Test: Error de conexi√≥n MCP se maneja correctamente

    Flujo:
    1. POST /api/v1/agent/execute
    2. MCP server no responde (timeout)
    3. Respuesta 202 pero resultado FAILED
    4. Webhook recibe error MCP_CONNECTION_ERROR
    5. Sistema no crashea, error contenido

    Validaciones:
    - Status 202 (aceptado pero fallar√°)
    - Webhook recibe status=failed
    - Error MCP_CONNECTION_ERROR en webhook
    - Retry logic ejecutado (si implementado)
    - Log completo del error
    """
```

##### E2E-4: Flujo con m√∫ltiples herramientas MCP
```python
async def test_e2e_multiple_mcp_tools_orchestration():
    """
    Test: Agente usa m√∫ltiples herramientas MCP en secuencia

    Flujo:
    1. Agente ValidadorDocumental ejecuta
    2. Llama consultar_expediente
    3. Llama listar_documentos
    4. Llama obtener_documento (m√∫ltiples veces)
    5. Llama a√±adir_anotacion
    6. Retorna resultado agregado

    Validaciones:
    - Todas las herramientas fueron llamadas
    - Orden correcto de llamadas
    - Datos pasados correctamente entre calls
    - Resultado final agrega todos los datos
    - tools_used lista completa en respuesta
    """
```

##### E2E-5: Flujo con webhook retry
```python
async def test_e2e_webhook_retry_on_failure():
    """
    Test: Webhook con retry autom√°tico en caso de fallo

    Flujo:
    1. Ejecuci√≥n exitosa del agente
    2. Primer intento webhook ‚Üí 500 Server Error
    3. Sistema hace retry (exponential backoff)
    4. Segundo intento ‚Üí 200 OK
    5. Ejecuci√≥n marcada como completa

    Validaciones:
    - 2 intentos de webhook registrados
    - Delay entre intentos (exponential backoff)
    - Segundo intento exitoso
    - Estado final: completed
    - Log registra ambos intentos
    """
```

##### E2E-6: Flujo con timeout de agente
```python
async def test_e2e_agent_timeout_handling():
    """
    Test: Timeout en ejecuci√≥n de agente

    Flujo:
    1. Agente tarda m√°s del timeout configurado
    2. Sistema cancela ejecuci√≥n
    3. Respuesta indica timeout
    4. Webhook notificado con TIMEOUT
    5. Recursos MCP liberados correctamente

    Validaciones:
    - Timeout detectado
    - Cancelaci√≥n limpia (no cuelga)
    - MCP registry cerrado
    - Webhook recibe TIMEOUT
    - Log indica timeout y cleanup
    """
```

##### E2E-7: Flujo con m√∫ltiples agentes concurrentes
```python
async def test_e2e_concurrent_agent_executions():
    """
    Test: M√∫ltiples ejecuciones concurrentes no interfieren

    Flujo:
    1. Lanzar 5 ejecuciones simult√°neas
    2. Diferentes expedientes/tareas
    3. Cada uno con su propio MCP registry
    4. Todas completan exitosamente
    5. Sin race conditions ni state leakage

    Validaciones:
    - 5 agent_run_id √∫nicos
    - Cada ejecuci√≥n independiente
    - Sin contaminaci√≥n de datos
    - Todos los webhooks llamados
    - Logs separados por run_id
    """
```

##### E2E-8: Flujo con diferentes tipos de agentes
```python
async def test_e2e_different_agent_types():
    """
    Test: Diferentes tipos de agentes funcionan correctamente

    Flujo:
    1. Ejecutar ValidadorDocumental ‚Üí √©xito
    2. Ejecutar AnalizadorSubvencion ‚Üí √©xito
    3. Ejecutar GeneradorInforme ‚Üí √©xito
    4. Cada uno usa herramientas MCP apropiadas
    5. Resultados espec√≠ficos a cada agente

    Validaciones:
    - 3 ejecuciones exitosas
    - Herramientas MCP correctas por agente
    - Estructura de resultado apropiada
    - Logs identifican tipo de agente
    """
```

**Archivo sugerido:** `tests/test_integration/test_e2e_flows.py`

---

### 2. Tests de Contrato (Contract Testing)

**Prioridad:** üî¥ ALTA
**Raz√≥n:** Garantizan que interfaces no cambian al introducir agentes reales
**Tests actuales:** 0
**Tests propuestos:** 12

#### Tests de Contrato Propuestos:

##### CONTRACT-1: Contrato AgentExecutor.execute()
```python
def test_contract_agent_executor_execute_signature():
    """
    Test: Firma de execute() cumple contrato

    Validaciones:
    - Par√°metros: token, expediente_id, tarea_id, agent_config
    - Retorna: AgentExecutionResult
    - Es async (coroutine)
    - Acepta kwargs para extensibilidad futura
    """
```

##### CONTRACT-2: Contrato AgentExecutionResult
```python
def test_contract_agent_execution_result_structure():
    """
    Test: Estructura de AgentExecutionResult es estable

    Validaciones:
    - Campos obligatorios: success, agent_run_id, message
    - Campos opcionales: resultado, error_codigo, tools_used, log_auditoria
    - Tipos correctos (Pydantic validation)
    - Serializable a JSON
    - Backward compatible (campos nuevos son opcionales)
    """
```

##### CONTRACT-3: Contrato BaseAgent.execute()
```python
def test_contract_base_agent_execute_interface():
    """
    Test: Interface de BaseAgent es estable para agentes reales

    Validaciones:
    - M√©todo execute() existe
    - Par√°metros: expediente_id, tarea_id, mcp_registry, logger
    - Retorna: Dict con estructura espec√≠fica
    - Es async
    - Subclases pueden extender sin romper
    """
```

##### CONTRACT-4: Contrato MCPClientRegistry
```python
def test_contract_mcp_client_registry_interface():
    """
    Test: Interface de MCP registry es estable

    Validaciones:
    - M√©todos: get_available_tools(), call_tool(), close()
    - call_tool acepta: tool_name, arguments, timeout
    - Retorna: Dict con result o error
    - Todos los m√©todos async
    - Maneja m√∫ltiples servers transparentemente
    """
```

##### CONTRACT-5: Contrato API POST /api/v1/agent/execute
```python
def test_contract_api_execute_request_response():
    """
    Test: Contrato de API es estable (OpenAPI spec)

    Request:
    - Headers: Authorization (Bearer JWT)
    - Body: expediente_id, tarea_id, agent_config, webhook_url

    Response 202:
    - Body: agent_run_id, message, webhook_url

    Response 4xx/5xx:
    - Body: detail, status_code

    Validaciones:
    - OpenAPI schema v√°lido
    - Campos opcionales marcados correctamente
    - Tipos coinciden con Pydantic models
    """
```

##### CONTRACT-6: Contrato Webhook Callback
```python
def test_contract_webhook_payload_structure():
    """
    Test: Payload de webhook es estable

    Validaciones:
    - Campos: agent_run_id, status, expediente_id, tarea_id
    - Campos opcionales: resultado, error_codigo, error_mensaje
    - Timestamp incluido
    - Formato JSON v√°lido
    - Versionado del schema (future-proof)
    """
```

##### CONTRACT-7: Contrato JWTClaims
```python
def test_contract_jwt_claims_structure():
    """
    Test: Estructura de JWT claims es estable

    Validaciones:
    - Claims est√°ndar: iss, sub, aud, exp, iat, nbf, jti
    - Claims custom: exp_id, permisos
    - Tipos correctos
    - Validaci√≥n Pydantic
    - Backward compatible con tokens antiguos
    """
```

##### CONTRACT-8: Contrato AuditLogger
```python
def test_contract_audit_logger_methods():
    """
    Test: Interface de AuditLogger es estable

    Validaciones:
    - M√©todos: info(), error(), warning(), redact_pii()
    - info/error aceptan: mensaje, **context
    - Retorna: None
    - Log lines escritas a archivo
    - Formato JSON lines
    """
```

##### CONTRACT-9: Contrato MCP Tool Call
```python
def test_contract_mcp_tool_call_format():
    """
    Test: Formato de llamada MCP tool es estable

    Request:
    - method: tools/call
    - params: name, arguments
    - headers: Authorization

    Response:
    - content: result o error
    - Formato JSON-RPC 2.0

    Validaciones:
    - Cumple spec MCP
    - Manejo de errores est√°ndar
    """
```

##### CONTRACT-10: Contrato Error Codes
```python
def test_contract_error_codes_are_stable():
    """
    Test: C√≥digos de error son estables y documentados

    Validaciones:
    - C√≥digos JWT: AUTH_TOKEN_EXPIRED, AUTH_INVALID_TOKEN, etc.
    - C√≥digos MCP: MCP_CONNECTION_ERROR, MCP_TOOL_ERROR, etc.
    - C√≥digos Agent: AGENT_EXECUTION_ERROR, AGENT_TIMEOUT, etc.
    - C√≥digos API: API_VALIDATION_ERROR, API_WEBHOOK_ERROR, etc.
    - Todos documentados en enum o constantes
    - No se eliminan c√≥digos (solo deprecan)
    """
```

##### CONTRACT-11: Contrato Pydantic Models Serialization
```python
def test_contract_pydantic_models_json_serializable():
    """
    Test: Todos los Pydantic models serializan a JSON

    Validaciones:
    - AgentConfigRequest ‚Üí JSON
    - ExecuteAgentRequest ‚Üí JSON
    - AgentExecutionResult ‚Üí JSON (v√≠a model_dump())
    - JWTClaims ‚Üí JSON
    - Sin p√©rdida de datos en round-trip
    """
```

##### CONTRACT-12: Contrato Backward Compatibility
```python
def test_contract_backward_compatibility_old_requests():
    """
    Test: Requests antiguos siguen funcionando

    Validaciones:
    - Request sin campos nuevos opcionales ‚Üí OK
    - Response con campos nuevos ‚Üí cliente antiguo ignora
    - Versionado de API (v1) permite evoluci√≥n
    - Deprecation warnings para features removidos
    """
```

**Archivo sugerido:** `tests/test_contracts/test_interfaces.py`

---

### 3. Tests de Error Handling y Resiliencia ‚úÖ COMPLETADO

**Prioridad:** üü° MEDIA-ALTA
**Raz√≥n:** Producci√≥n requiere manejo robusto de errores
**Tests actuales:** 15 (12 activos + 3 skip)
**Tests propuestos:** 15

**Estado:** ‚úÖ IMPLEMENTADO (2025-12-21)

#### Tests de Error Handling Propuestos:

##### ERROR-1: MCP Server Down
```python
async def test_error_mcp_server_completely_down():
    """
    Test: MCP server completamente ca√≠do

    Escenario:
    - MCP server no responde (connection refused)
    - Sistema intenta conectar
    - Timeout despu√©s de N segundos
    - Error propagado limpiamente

    Validaciones:
    - No crashea la aplicaci√≥n
    - Error MCP_CONNECTION_ERROR
    - Mensaje descriptivo
    - Log con detalles de conexi√≥n
    - Registry cleanup correcto
    """
```

##### ERROR-2: MCP Tool Error
```python
async def test_error_mcp_tool_execution_fails():
    """
    Test: Herramienta MCP falla durante ejecuci√≥n

    Escenario:
    - Tool consultar_expediente retorna error
    - Error 404 expediente no encontrado
    - Agente recibe error
    - Decide c√≥mo continuar

    Validaciones:
    - Error MCP_TOOL_ERROR
    - Mensaje incluye nombre del tool
    - Stack trace disponible en logs
    - Agente puede manejar error
    """
```

##### ERROR-3: Network Timeout
```python
async def test_error_network_timeout_during_mcp_call():
    """
    Test: Timeout de red durante llamada MCP

    Escenario:
    - MCP call tarda >timeout configurado
    - Sistema cancela request
    - Error propagado a agente

    Validaciones:
    - Timeout detectado
    - Request cancelado (no cuelga)
    - Error MCP_TIMEOUT
    - Recursos liberados
    """
```

##### ERROR-4: Invalid JWT Format
```python
def test_error_malformed_jwt_token():
    """
    Test: JWT malformado es rechazado

    Escenarios:
    - Token no es JWT v√°lido
    - Token con firma inv√°lida
    - Token sin claims requeridos
    - Token con claim exp_id null

    Validaciones:
    - Error AUTH_INVALID_TOKEN
    - Mensaje espec√≠fico del problema
    - No expone informaci√≥n sensible
    - Log registra intento
    """
```

##### ERROR-5: Webhook Delivery Failure
```python
async def test_error_webhook_delivery_fails_permanently():
    """
    Test: Webhook falla despu√©s de todos los retries

    Escenario:
    - Webhook endpoint retorna 500
    - Sistema intenta N veces
    - Todos fallan
    - Sistema marca como failed

    Validaciones:
    - N retries ejecutados
    - Backoff exponencial aplicado
    - Estado final: webhook_failed
    - Log con todos los intentos
    - Ejecuci√≥n marcada como completa (no cuelga)
    """
```

##### ERROR-6: Agent Crashes
```python
async def test_error_agent_raises_unhandled_exception():
    """
    Test: Agente lanza excepci√≥n no manejada

    Escenario:
    - Agente tiene bug (NoneType error)
    - Excepci√≥n no es capturada por agente
    - Sistema la captura en executor

    Validaciones:
    - Error AGENT_EXECUTION_ERROR
    - Stack trace completo en log
    - MCP registry cerrado
    - Webhook notificado de error
    - Sistema sigue funcionando (isolated failure)
    """
```

##### ERROR-7: MCP JSON-RPC Error
```python
async def test_error_mcp_jsonrpc_error_response():
    """
    Test: MCP retorna error JSON-RPC v√°lido

    Escenario:
    - MCP retorna error code -32600 (Invalid Request)
    - Mensaje de error del servidor
    - Sistema lo convierte a MCP_TOOL_ERROR

    Validaciones:
    - Error code preservado
    - Mensaje de MCP incluido
    - Log con request/response completo
    """
```

##### ERROR-8: Database Unavailable (future-proof)
```python
@pytest.mark.skip("Para Paso 4: cuando se agregue BD")
async def test_error_database_connection_lost():
    """
    Test: Base de datos no disponible

    Escenario:
    - Conexi√≥n BD se pierde
    - Sistema detecta error
    - Fallback a logs en archivo

    Validaciones:
    - Error DB_CONNECTION_ERROR
    - Sistema sigue funcionando degraded mode
    - Logs escritos a archivo
    - Retry autom√°tico de conexi√≥n
    """
```

##### ERROR-9: Invalid Agent Configuration
```python
def test_error_invalid_agent_configuration():
    """
    Test: Configuraci√≥n de agente inv√°lida

    Escenarios:
    - Nombre de agente desconocido
    - system_prompt vac√≠o
    - herramientas no disponibles en MCP
    - modelo LLM inv√°lido

    Validaciones:
    - Error AGENT_CONFIG_ERROR
    - Mensaje espec√≠fico del problema
    - Validaci√≥n Pydantic activada
    - No se intenta ejecuci√≥n
    """
```

##### ERROR-10: Concurrent Modification Conflict
```python
async def test_error_concurrent_modification_same_expediente():
    """
    Test: Dos agentes intentan modificar mismo expediente

    Escenario:
    - Agente A actualiza expediente
    - Agente B intenta actualizar mismo expediente
    - MCP detecta conflicto
    - Uno falla con CONFLICT error

    Validaciones:
    - Error MCP_CONFLICT
    - Versi√≥n del expediente preservada
    - Agente puede retry
    - No se pierde ninguna actualizaci√≥n
    """
```

##### ERROR-11: Out of Memory (stress)
```python
@pytest.mark.slow
@pytest.mark.skip("Solo para stress testing")
async def test_error_out_of_memory_handling():
    """
    Test: Sistema maneja out of memory gracefully

    Escenario:
    - Agente procesa documento enorme
    - Memoria se agota
    - Sistema detecta y cancela

    Validaciones:
    - No crashea proceso completo
    - Error AGENT_RESOURCE_ERROR
    - Memoria liberada
    - Otros agentes siguen funcionando
    """
```

##### ERROR-12: Invalid Webhook URL
```python
def test_error_invalid_webhook_url_format():
    """
    Test: URL de webhook inv√°lida es rechazada

    Escenarios:
    - URL no HTTP/HTTPS
    - URL con localhost (SSRF)
    - URL con IP privada
    - URL malformada

    Validaciones:
    - Error API_VALIDATION_ERROR
    - Request rechazado inmediatamente (antes de ejecutar)
    - Validaci√≥n SSRF funciona
    - Mensaje claro del problema
    """
```

##### ERROR-13: MCP Authorization Error
```python
async def test_error_mcp_authorization_denied():
    """
    Test: MCP rechaza por permisos insuficientes

    Escenario:
    - JWT con permiso 'consulta'
    - Agente intenta tool que requiere 'gestion'
    - MCP rechaza con 403

    Validaciones:
    - Error MCP_PERMISSION_DENIED
    - Mensaje indica permiso faltante
    - Agente notificado del error
    - No retry (error definitivo)
    """
```

##### ERROR-14: PII Redaction Failure
```python
def test_error_pii_redaction_handles_invalid_data():
    """
    Test: PII redactor maneja datos inv√°lidos

    Escenarios:
    - String con encoding inv√°lido
    - Datos binarios en log
    - Ciclos de referencia en objetos

    Validaciones:
    - No crashea el redactor
    - Fallback: redacta todo el objeto
    - Log warning de redaction failure
    - Sistema contin√∫a funcionando
    """
```

##### ERROR-15: API Rate Limiting (future)
```python
@pytest.mark.skip("Para Paso 4: cuando se agregue rate limiting")
async def test_error_api_rate_limit_exceeded():
    """
    Test: Rate limiting protege el sistema

    Escenario:
    - Cliente env√≠a >N requests/segundo
    - Sistema rechaza con 429 Too Many Requests
    - Header Retry-After incluido

    Validaciones:
    - Status 429
    - Header Retry-After presente
    - Rate limit por IP/cliente
    - Log del rate limit
    """
```

**Archivo sugerido:** `tests/test_error_handling/test_resilience.py`

---

### 4. Tests de Concurrencia y Performance

**Prioridad:** üü° MEDIA
**Raz√≥n:** Importante para producci√≥n, pero no bloqueante para Paso 3
**Tests actuales:** 1
**Tests propuestos:** 8

#### Tests de Concurrencia Propuestos:

##### PERF-1: Concurrencia B√°sica
```python
@pytest.mark.slow
async def test_perf_concurrent_agent_executions_no_interference():
    """
    Test: 10 ejecuciones concurrentes sin interferencia

    Escenario:
    - Lanzar 10 ejecuciones simult√°neas
    - Diferentes expedientes
    - Medir tiempo total vs secuencial

    Validaciones:
    - Todas completan exitosamente
    - Sin race conditions
    - Speedup razonable (>5x)
    - Memoria estable
    """
```

##### PERF-2: MCP Connection Pool
```python
async def test_perf_mcp_connection_reuse():
    """
    Test: Conexiones MCP se reusan eficientemente

    Escenario:
    - M√∫ltiples calls a mismo MCP server
    - Verificar que se reusan conexiones HTTP

    Validaciones:
    - 1 conexi√≥n TCP para N requests
    - Connection pooling funciona
    - Mejor latencia en calls subsecuentes
    """
```

##### PERF-3: Memory Leak Detection
```python
@pytest.mark.slow
async def test_perf_no_memory_leaks_after_executions():
    """
    Test: No hay memory leaks en ejecuciones repetidas

    Escenario:
    - Ejecutar 100 agentes secuencialmente
    - Medir memoria antes/despu√©s

    Validaciones:
    - Memoria se mantiene estable
    - GC funciona correctamente
    - No acumulaci√≥n de objetos
    """
```

##### PERF-4: API Response Time
```python
@pytest.mark.slow
def test_perf_api_response_time_p95():
    """
    Test: P95 de response time de API < 500ms

    Escenario:
    - 1000 requests a API
    - Medir latencias

    Validaciones:
    - P50 < 100ms
    - P95 < 500ms
    - P99 < 1000ms
    """
```

##### PERF-5: MCP Tool Call Latency
```python
async def test_perf_mcp_tool_call_latency():
    """
    Test: Latencia de MCP tool call razonable

    Escenario:
    - Llamar tool simple 100 veces
    - Medir latencia promedio

    Validaciones:
    - Promedio < 50ms
    - Sin degradaci√≥n con tiempo
    """
```

##### PERF-6: Webhook Delivery Time
```python
@pytest.mark.slow
async def test_perf_webhook_delivery_time():
    """
    Test: Webhooks se env√≠an r√°pidamente

    Escenario:
    - Agente completa ejecuci√≥n
    - Medir tiempo hasta webhook enviado

    Validaciones:
    - Webhook enviado < 100ms despu√©s de completion
    - No queueing si webhook responde r√°pido
    """
```

##### PERF-7: Stress Test
```python
@pytest.mark.slow
@pytest.mark.skip("Solo CI nocturno")
async def test_perf_stress_100_concurrent_agents():
    """
    Test: Sistema maneja 100 agentes concurrentes

    Escenario:
    - 100 ejecuciones simult√°neas
    - Sistema bajo carga

    Validaciones:
    - Todas completan (puede tardar)
    - Sin crashes
    - Error rate < 1%
    """
```

##### PERF-8: Resource Cleanup Under Load
```python
@pytest.mark.slow
async def test_perf_resource_cleanup_under_load():
    """
    Test: Recursos se limpian correctamente bajo carga

    Escenario:
    - 50 ejecuciones concurrentes
    - Algunas con errores
    - Verificar cleanup

    Validaciones:
    - Conexiones MCP cerradas
    - Archivos temporales eliminados
    - Memoria liberada
    - No file descriptor leaks
    """
```

**Archivo sugerido:** `tests/test_performance/test_concurrency.py`

---

### 5. Tests de Seguridad Adicionales

**Prioridad:** üü° MEDIA
**Raz√≥n:** Buena cobertura actual, pero se puede mejorar
**Tests actuales:** 19 (JWT) + 12 (PII)
**Tests propuestos:** 10

#### Tests de Seguridad Propuestos:

##### SEC-1: JWT Replay Attack
```python
def test_sec_jwt_replay_attack_prevention():
    """
    Test: JWT con jti duplicado es rechazado (si se implementa)

    Escenario:
    - Token v√°lido usado 2 veces
    - jti deber√≠a ser √∫nico

    Validaciones:
    - Segunda vez rechazada (si se implementa cache jti)
    - O documentar que no se previene (stateless)
    """
```

##### SEC-2: SSRF Prevention
```python
def test_sec_webhook_url_ssrf_prevention():
    """
    Test: URLs peligrosas son rechazadas

    URLs rechazadas:
    - http://localhost:8000
    - http://127.0.0.1
    - http://192.168.1.1
    - http://169.254.169.254 (AWS metadata)
    - http://10.0.0.1
    - file:// protocol

    Validaciones:
    - Todas rechazadas con VALIDATION_ERROR
    - Solo URLs p√∫blicas permitidas
    """
```

##### SEC-3: SQL Injection (future-proof)
```python
@pytest.mark.skip("Para Paso 4: cuando se agregue BD")
def test_sec_sql_injection_prevention():
    """
    Test: Queries parametrizadas previenen SQL injection

    Escenario:
    - Input con ' OR 1=1--
    - Sistema usa parameterized queries

    Validaciones:
    - No SQL injection
    - ORM escapa correctamente
    """
```

##### SEC-4: XSS Prevention
```python
def test_sec_api_response_sanitizes_html():
    """
    Test: Respuestas API no incluyen HTML sin escapar

    Escenario:
    - Agente retorna <script>alert(1)</script>
    - API retorna como JSON (auto-escaped)

    Validaciones:
    - Content-Type: application/json
    - HTML escaped en strings
    - No interpretaci√≥n de HTML
    """
```

##### SEC-5: Sensitive Data Logging
```python
def test_sec_sensitive_data_not_logged():
    """
    Test: Datos sensibles nunca en logs

    Escenario:
    - JWT token en request
    - PII en datos de expediente
    - Secrets en environment

    Validaciones:
    - JWT redacted en logs
    - PII redacted (8 tipos)
    - Secrets nunca loggeados
    """
```

##### SEC-6: Authorization Escalation
```python
def test_sec_cannot_access_different_expediente():
    """
    Test: No se puede acceder a expediente no autorizado

    Escenario:
    - JWT con exp_id=EXP-001
    - Request para exp_id=EXP-002

    Validaciones:
    - Error AUTH_EXPEDIENTE_MISMATCH
    - Acceso denegado
    - Intento loggeado
    """
```

##### SEC-7: Header Injection
```python
def test_sec_header_injection_prevention():
    """
    Test: Headers malformados son rechazados

    Escenario:
    - Header con \\r\\n injection
    - Intento de inyectar headers adicionales

    Validaciones:
    - FastAPI rechaza headers malformados
    - No header injection posible
    """
```

##### SEC-8: Path Traversal (future)
```python
@pytest.mark.skip("Cuando se agregue file upload")
def test_sec_path_traversal_prevention():
    """
    Test: Path traversal prevenido en file operations

    Escenario:
    - Filename con ../../../etc/passwd
    - Sistema sanitiza path

    Validaciones:
    - Path normalizado
    - Solo permite directorio configurado
    """
```

##### SEC-9: DoS via Large Payloads
```python
def test_sec_large_payload_rejected():
    """
    Test: Payloads enormes son rechazados

    Escenario:
    - Request con body de 100MB
    - FastAPI lo rechaza

    Validaciones:
    - Error 413 Payload Too Large
    - L√≠mite configurado (ej: 10MB)
    """
```

##### SEC-10: Timing Attack on JWT
```python
def test_sec_jwt_validation_constant_time():
    """
    Test: Validaci√≥n JWT es constant-time

    Escenario:
    - JWT v√°lido vs inv√°lido
    - Medir tiempo de validaci√≥n

    Validaciones:
    - Diferencia < 10ms (evita timing attacks)
    - Usa comparaci√≥n constant-time para firma
    """
```

**Archivo sugerido:** `tests/test_security/test_additional_security.py`

---

### 6. Tests de Regresi√≥n para Paso 3

**Prioridad:** üî¥ ALTA (antes de Paso 3)
**Raz√≥n:** Garantizan que agentes reales no rompen comportamiento actual
**Tests actuales:** 0
**Tests propuestos:** 8

#### Tests de Regresi√≥n Propuestos:

##### REG-1: Mock Agent Baseline
```python
def test_regression_mock_agent_behavior_baseline():
    """
    Test: Capturar comportamiento actual de agentes mock

    Escenario:
    - Ejecutar ValidadorDocumental con datos conocidos
    - Guardar resultado exacto como baseline

    Validaciones:
    - Resultado id√©ntico a baseline guardado
    - Si cambia, test falla (regression detected)
    - Baseline versionado en git
    """
```

##### REG-2: API Response Format Stability
```python
def test_regression_api_response_format_unchanged():
    """
    Test: Formato de respuesta API no cambia

    Escenario:
    - POST /api/v1/agent/execute
    - Verificar estructura exacta de respuesta

    Validaciones:
    - Campos esperados presentes
    - Sin campos removidos
    - Tipos de datos correctos
    - Schema validation
    """
```

##### REG-3: Webhook Payload Format Stability
```python
def test_regression_webhook_payload_unchanged():
    """
    Test: Payload de webhook mantiene formato

    Validaciones:
    - Campos obligatorios presentes
    - Estructura JSON estable
    - Clientes existentes no se rompen
    """
```

##### REG-4: Error Codes Stability
```python
def test_regression_error_codes_not_changed():
    """
    Test: C√≥digos de error no cambian

    Validaciones:
    - Todos los c√≥digos de error existentes preservados
    - Mensajes de error no cambian radicalmente
    - C√≥digos nuevos OK, pero no remover
    """
```

##### REG-5: MCP Tool Usage Pattern
```python
def test_regression_mcp_tool_usage_pattern():
    """
    Test: Patr√≥n de uso de MCP tools no cambia

    Escenario:
    - Agente ValidadorDocumental
    - Verificar qu√© tools usa y en qu√© orden

    Validaciones:
    - Mismo conjunto de tools
    - Orden similar (puede variar con AI)
    - No tools faltantes
    """
```

##### REG-6: Performance Baseline
```python
@pytest.mark.slow
def test_regression_performance_not_degraded():
    """
    Test: Performance no se degrada

    Escenario:
    - Ejecutar 10 agentes
    - Medir tiempo total

    Validaciones:
    - Tiempo < baseline * 1.2 (20% tolerancia)
    - No degradaci√≥n significativa
    """
```

##### REG-7: Log Format Stability
```python
def test_regression_log_format_unchanged():
    """
    Test: Formato de logs de auditor√≠a no cambia

    Validaciones:
    - JSON lines format
    - Campos obligatorios presentes
    - Parsers externos no se rompen
    """
```

##### REG-8: Agent Interface Compatibility
```python
def test_regression_agent_interface_backward_compatible():
    """
    Test: Interface de agente es backward compatible

    Escenario:
    - Crear agente mock simple (como los actuales)
    - Verificar que sigue funcionando con agentes reales

    Validaciones:
    - BaseAgent interface no cambi√≥
    - M√©todos nuevos son opcionales
    - Agentes antiguos siguen funcionando
    """
```

**Archivo sugerido:** `tests/test_regression/test_paso3_compatibility.py`

---

### 7. Tests de Datos y Validaci√≥n

**Prioridad:** üü¢ BAJA-MEDIA
**Raz√≥n:** Pydantic ya valida, pero casos edge pueden mejorarse
**Tests actuales:** Impl√≠cito en otros tests
**Tests propuestos:** 6

#### Tests de Validaci√≥n Propuestos:

##### DATA-1: Pydantic Validation Comprehensive
```python
def test_data_pydantic_models_validate_edge_cases():
    """
    Test: Modelos Pydantic validan casos edge

    Casos:
    - Strings vac√≠os
    - Campos None en opcionales
    - Listas vac√≠as
    - N√∫meros negativos
    - Strings muy largos (>10000 chars)

    Validaciones:
    - Validation error apropiado
    - Mensajes claros
    """
```

##### DATA-2: Date/Time Handling
```python
def test_data_datetime_formats_accepted():
    """
    Test: Diferentes formatos de fecha aceptados

    Formatos:
    - ISO 8601 con Z
    - ISO 8601 con +00:00
    - Unix timestamp

    Validaciones:
    - Todos parseados correctamente
    - Conversi√≥ni√≥n a UTC
    - Timezone aware
    """
```

##### DATA-3: Unicode Handling
```python
def test_data_unicode_characters_handled():
    """
    Test: Caracteres Unicode manejados correctamente

    Casos:
    - Nombres con tildes: Jos√©, Mar√≠a
    - Emojis: üéâ (si se permiten)
    - Caracteres especiales: ‚Ç¨, ¬£

    Validaciones:
    - Encoding UTF-8 correcto
    - No corrupci√≥n de datos
    - JSON serialization OK
    """
```

##### DATA-4: Numeric Precision
```python
def test_data_numeric_precision_preserved():
    """
    Test: Precisi√≥n num√©rica preservada

    Casos:
    - Decimales: 1234.56789
    - Muy grandes: 1e308
    - Muy peque√±os: 1e-308

    Validaciones:
    - Sin p√©rdida de precisi√≥n
    - JSON number format
    """
```

##### DATA-5: List/Dict Edge Cases
```python
def test_data_list_dict_edge_cases():
    """
    Test: Listas y dicts edge cases

    Casos:
    - Lista vac√≠a: []
    - Dict vac√≠o: {}
    - Nested deep: 10 niveles
    - Listas grandes: 10000 elementos

    Validaciones:
    - Serialization funciona
    - No stack overflow
    - Performance aceptable
    """
```

##### DATA-6: URL Validation
```python
def test_data_url_validation_comprehensive():
    """
    Test: Validaci√≥n de URLs completa

    URLs v√°lidas:
    - https://example.com
    - https://example.com:8443
    - https://example.com/path?query=1

    URLs inv√°lidas:
    - javascript:alert(1)
    - data:text/html,<script>
    - ftp://example.com

    Validaciones:
    - Pydantic HttpUrl funciona
    - Solo HTTP/HTTPS permitidos
    """
```

**Archivo sugerido:** `tests/test_data_validation/test_pydantic_edge_cases.py`

---

## üìÇ Estructura de Tests Propuesta

```
tests/
‚îú‚îÄ‚îÄ test_api/                      # 22 tests existentes
‚îÇ   ‚îú‚îÄ‚îÄ test_agent_endpoints.py
‚îÇ   ‚îú‚îÄ‚îÄ test_health_endpoints.py
‚îÇ   ‚îî‚îÄ‚îÄ test_webhook_validation.py
‚îÇ
‚îú‚îÄ‚îÄ test_mcp/                      # 34 tests existentes
‚îÇ   ‚îú‚îÄ‚îÄ test_auth.py
‚îÇ   ‚îú‚îÄ‚îÄ test_resources.py
‚îÇ   ‚îú‚îÄ‚îÄ test_server_http.py
‚îÇ   ‚îî‚îÄ‚îÄ test_tools.py
‚îÇ
‚îú‚îÄ‚îÄ test_backoffice/               # 87 tests existentes
‚îÇ   ‚îú‚îÄ‚îÄ test_executor.py
‚îÇ   ‚îú‚îÄ‚îÄ test_jwt_validator.py
‚îÇ   ‚îú‚îÄ‚îÄ test_logging.py
‚îÇ   ‚îú‚îÄ‚îÄ test_mcp_integration.py
‚îÇ   ‚îî‚îÄ‚îÄ test_protocols.py
‚îÇ
‚îú‚îÄ‚îÄ test_contracts/                # 12 tests existentes ‚úÖ
‚îÇ   ‚îî‚îÄ‚îÄ test_interfaces.py
‚îÇ
‚îú‚îÄ‚îÄ test_error_handling/           # 15 tests existentes ‚úÖ
‚îÇ   ‚îî‚îÄ‚îÄ test_resilience.py
‚îÇ
‚îú‚îÄ‚îÄ test_integration/              # NUEVO: 8 tests E2E propuestos
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py
‚îÇ   ‚îî‚îÄ‚îÄ test_e2e_flows.py
‚îÇ
‚îú‚îÄ‚îÄ test_performance/              # NUEVO: 8 tests de performance propuestos
‚îÇ   ‚îî‚îÄ‚îÄ test_concurrency.py
‚îÇ
‚îú‚îÄ‚îÄ test_security/                 # NUEVO: 10 tests de seguridad propuestos
‚îÇ   ‚îî‚îÄ‚îÄ test_additional_security.py
‚îÇ
‚îú‚îÄ‚îÄ test_regression/               # NUEVO: 8 tests de regresi√≥n propuestos
‚îÇ   ‚îî‚îÄ‚îÄ test_paso3_compatibility.py
‚îÇ
‚îî‚îÄ‚îÄ test_data_validation/          # NUEVO: 6 tests de validaci√≥n propuestos
    ‚îî‚îÄ‚îÄ test_pydantic_edge_cases.py
```

**Tests implementados:** 27 (12 contracts + 15 error handling) ‚úÖ
**Tests propuestos restantes:** +40 tests nuevos
**Total actual:** 170 tests (166 pass + 4 skip)
**Total proyectado final:** 142 + 67 = **209 tests**

---

## üéØ Plan de Implementaci√≥n Sugerido

### Fase 1: Tests Cr√≠ticos para Paso 2 (Prioridad ALTA)
**Duraci√≥n:** 1-2 semanas
**Tests:** 28

1. **E2E Tests (8)** - Validar flujos completos
2. **Contract Tests (12)** - Garantizar estabilidad de interfaces
3. **Regression Tests (8)** - Preparar para Paso 3

**Objetivo:** Asegurar que API REST est√° lista para producci√≥n

### Fase 2: Tests de Robustez (Prioridad MEDIA)
**Duraci√≥n:** 1 semana
**Tests:** 25

1. **Error Handling (15)** - Cubrir todos los casos de error
2. **Security (10)** - Fortalecer seguridad

**Objetivo:** Sistema resiliente ante errores

### Fase 3: Tests de Performance (Prioridad BAJA)
**Duraci√≥n:** 1 semana
**Tests:** 14

1. **Concurrency (8)** - Validar comportamiento bajo carga
2. **Data Validation (6)** - Edge cases de datos

**Objetivo:** Sistema listo para carga de producci√≥n

---

## üîß Herramientas y Configuraci√≥n Recomendadas

### pytest-asyncio
```ini
# pytest.ini (ya configurado)
asyncio_mode = strict
```

### pytest-timeout
```bash
pip install pytest-timeout
```

```python
@pytest.mark.timeout(30)  # Test no debe tardar >30s
async def test_e2e_...():
    ...
```

### pytest-benchmark
```bash
pip install pytest-benchmark
```

```python
def test_perf_api_latency(benchmark):
    result = benchmark(lambda: call_api())
    assert result < 100  # ms
```

### pytest-httpx (para mock HTTP)
```bash
pip install pytest-httpx
```

```python
def test_webhook_delivery(httpx_mock):
    httpx_mock.add_response(url="https://example.com/webhook", status_code=200)
    # Test webhook delivery
```

### Coverage m√≠nimo
```ini
# pytest.ini
[coverage:report]
fail_under = 80  # 80% coverage m√≠nimo
```

---

## üìä M√©tricas de √âxito

### Cobertura de Tests
- **Actual:** ~75% estimado
- **Objetivo Fase 1:** 85%
- **Objetivo Fase 2:** 90%
- **Objetivo Final:** 95%

### Tests por Categor√≠a
| Categor√≠a | Actual | Objetivo |
|-----------|--------|----------|
| Unit | 80 | 100 |
| Integration | 15 | 35 |
| E2E | 0 | 8 |
| Contract | 0 | 12 |
| Security | 31 | 41 |
| Performance | 1 | 9 |
| **TOTAL** | **142** | **209** |

### Calidad
- **Flakiness:** 0% (tests deben ser deterministas)
- **Test Execution Time:** <5 minutos suite completa
- **CI/CD:** Todos los tests pasan en cada commit

---

## üöÄ Pr√≥ximos Pasos Inmediatos

### Acci√≥n 1: Crear estructura de carpetas
```bash
mkdir -p tests/test_integration
mkdir -p tests/test_contracts
mkdir -p tests/test_error_handling
mkdir -p tests/test_performance
mkdir -p tests/test_security
mkdir -p tests/test_regression
mkdir -p tests/test_data_validation
```

### Acci√≥n 2: Implementar tests E2E (Fase 1)
Comenzar con `tests/test_integration/test_e2e_flows.py` - 8 tests m√°s cr√≠ticos

### Acci√≥n 3: Implementar tests de contrato (Fase 1)
Definir contratos en `tests/test_contracts/test_interfaces.py` - 12 tests

### Acci√≥n 4: Configurar CI/CD
Asegurar que todos los tests corren en cada PR

---

## üìù Notas Finales

### ¬øPor qu√© estos tests?

1. **E2E:** Validan que el sistema funciona de punta a punta
2. **Contratos:** Garantizan que cambios no rompen integraciones
3. **Errores:** Producci√≥n siempre tiene errores, debemos manejarlos
4. **Performance:** Sistema debe escalar
5. **Seguridad:** Protecci√≥n contra ataques
6. **Regresi√≥n:** Cambios futuros no rompen lo actual

### ¬øCu√°ndo NO escribir un test?

- Test trivial que no aporta valor
- Test que duplica otro test
- Test que es m√°s c√≥digo que la feature
- Test flaky (aleatorio)

### Filosof√≠a

> "Tests no son para encontrar bugs, son para **prevenir** que bugs lleguen a producci√≥n"

---

---

## ‚úÖ Estado de Implementaci√≥n

**√öltima actualizaci√≥n:** 2025-12-21

### Tests de Error Handling - COMPLETADOS ‚úÖ

**Archivo:** `tests/test_error_handling/test_resilience.py`

**Tests implementados: 15 (12 activos + 3 skip)**

| Test | Estado | Descripci√≥n |
|------|--------|-------------|
| ERROR-1 | ‚úÖ PASS | MCP Server Down |
| ERROR-2 | ‚úÖ PASS | MCP Tool Error |
| ERROR-3 | ‚úÖ PASS | Network Timeout |
| ERROR-4 | ‚úÖ PASS | Invalid JWT Format |
| ERROR-5 | ‚úÖ PASS | Webhook Delivery Failure (con retry) |
| ERROR-6 | ‚úÖ PASS | Agent Crashes |
| ERROR-7 | ‚úÖ PASS | MCP JSON-RPC Error |
| ERROR-8 | ‚è≠Ô∏è SKIP | Database Unavailable (Paso 4) |
| ERROR-9 | ‚úÖ PASS | Invalid Agent Configuration |
| ERROR-10 | ‚úÖ PASS | Concurrent Modification Conflict |
| ERROR-11 | ‚è≠Ô∏è SKIP | Out of Memory (stress testing) |
| ERROR-12 | ‚úÖ PASS | Invalid Webhook URL (SSRF) |
| ERROR-13 | ‚úÖ PASS | MCP Authorization Error |
| ERROR-14 | ‚úÖ PASS | PII Redaction Failure |
| ERROR-15 | ‚è≠Ô∏è SKIP | API Rate Limiting (Paso 4) |

**C√≥digo de producci√≥n modificado:**
1. `src/backoffice/models.py` - Agregado c√≥digo `MCP_CONFLICT`
2. `src/backoffice/mcp/client.py` - Manejo HTTP 409
3. `src/backoffice/logging/pii_redactor.py` - Error handling robusto
4. `src/api/services/webhook.py` - Funci√≥n `send_webhook_with_retry()`

**M√©tricas:**
- Total tests: 170 (166 pass + 4 skip)
- Tests nuevos: 15 (12 pass + 3 skip)
- C√≥digo producci√≥n: ~95 LOC
- C√≥digo tests: ~750 LOC
- Tiempo ejecuci√≥n: ~0.6s (error handling), ~3s (suite completa)

---

### Tests de Contracts - COMPLETADOS ‚úÖ

**Archivo:** `tests/test_contracts/test_interfaces.py`

**Tests implementados: 12 (100% pass)**

| Test | Estado | Descripci√≥n |
|------|--------|-------------|
| CONTRACT-1 | ‚úÖ PASS | MCPClient.call_tool signature |
| CONTRACT-2 | ‚úÖ PASS | MCPClient.list_tools signature |
| CONTRACT-3 | ‚úÖ PASS | MCPClient exception contracts |
| CONTRACT-4 | ‚úÖ PASS | MCPClient async behavior |
| CONTRACT-5 | ‚úÖ PASS | AgentRegistry.get signature |
| CONTRACT-6 | ‚úÖ PASS | AgentRegistry.list signature |
| CONTRACT-7 | ‚úÖ PASS | AgentRegistry exception contracts |
| CONTRACT-8 | ‚úÖ PASS | AgentRegistry lifecycle |
| CONTRACT-9 | ‚úÖ PASS | ConfigLoader.load signature |
| CONTRACT-10 | ‚úÖ PASS | ConfigLoader.validate signature |
| CONTRACT-11 | ‚úÖ PASS | ConfigLoader exception contracts |
| CONTRACT-12 | ‚úÖ PASS | ConfigLoader immutability |

**Prop√≥sito:**
- Garantizar estabilidad de interfaces p√∫blicas
- Detectar cambios incompatibles antes de Paso 3
- Documentar contratos esperados para agentes reales

**M√©tricas:**
- Total tests: 12 (100% pass)
- C√≥digo tests: ~480 LOC
- Tiempo ejecuci√≥n: ~0.3s
- Cobertura: Interfaces cr√≠ticas para backward compatibility

**Integraci√≥n:**
- Incluidos en `run-tests.sh` junto con otras suites
- Ejecutados autom√°ticamente en cada run
- Parte del total de 170 tests

---

**Documento creado:** 2025-12-20
**Implementaci√≥n completada:** 2025-12-21
**Autor:** Claude Code
**Estado:** ‚úÖ IMPLEMENTADO - Tests de Error Handling y Contracts completos
