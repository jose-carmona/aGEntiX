# Plan de Mejoras - Tests aGEntiX

## Objetivo

Pasar de **119/152 tests ejecutÃ¡ndose (78%)** a **152/152 tests ejecutÃ¡ndose (100%)** con cÃ³digo limpio, mantenible y sin antipatrones.

---

## Fase 1: Arreglos CrÃ­ticos âš¡

**DuraciÃ³n estimada:** 1-2 horas
**Prioridad:** CRÃTICA
**Objetivo:** Hacer que los 33 tests de API se ejecuten

### 1.1 Fix API Tests Imports

**Archivos a modificar:**
- `tests/api/conftest.py`

**Cambios:**

```python
# ANTES (tests/api/conftest.py)
import os
from pathlib import Path

root_dir = Path(__file__).parent.parent.parent
os.chdir(str(root_dir))  # âŒ AntipatrÃ³n

# DESPUÃ‰S (tests/api/conftest.py)
# ELIMINAR todo el contenido
# El conftest.py global ya configura sys.path correctamente
```

**ValidaciÃ³n:**
```bash
pytest tests/api/ -v
# Debe ejecutar 33 tests (actualmente 0)
```

---

### 1.2 Consolidar sys.path en Conftest Global

**Archivos a modificar:**
- `tests/test_mcp/conftest.py` (eliminar lÃ­neas 15-18)
- `tests/test_mcp/fixtures/tokens.py` (eliminar lÃ­nea 13)

**Cambios en `tests/test_mcp/conftest.py`:**

```python
# ANTES (lÃ­neas 14-18)
# Configurar PYTHONPATH para imports desde src/ y fixtures locales
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root / "src"))
# Agregar directorio de tests para imports de fixtures
sys.path.insert(0, str(Path(__file__).parent))

# DESPUÃ‰S
# ELIMINAR estas lÃ­neas - ya estÃ¡n en conftest.py global
```

**Cambios en `tests/test_mcp/fixtures/tokens.py`:**

```python
# ANTES (lÃ­neas 11-13)
# Configurar path para imports (necesario en entorno de test)
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "../.."))

# DESPUÃ‰S
# ELIMINAR estas lÃ­neas - fixtures se importan con from fixtures.tokens
```

**ValidaciÃ³n:**
```bash
# Verificar que no hay mÃºltiples entradas de src/ en sys.path
python -c "import sys; print([p for p in sys.path if 'aGEntiX' in p])"
# Debe mostrar solo 2 paths: /workspaces/aGEntiX y /workspaces/aGEntiX/src
```

---

### 1.3 Setup Environment con Autouse Fixture

**Archivo a modificar:**
- `conftest.py` (raÃ­z)

**Cambios:**

```python
# Agregar al final de conftest.py
@pytest.fixture(scope="session")
def test_constants():
    """Constantes compartidas entre todos los tests"""
    return {
        "jwt_secret": "test-secret-key",
        "jwt_algorithm": "HS256",
        "issuer": "agentix-bpmn",
        "subject": "AutomÃ¡tico",
        "audience": "agentix-mcp-expedientes",
        "default_exp_ids": ["EXP-2024-001", "EXP-2024-002", "EXP-2024-003"]
    }


@pytest.fixture(scope="session", autouse=True)
def setup_test_environment(test_constants):
    """
    Configura environment variables para todos los tests.
    autouse=True: se ejecuta automÃ¡ticamente.
    """
    import os

    original_env = {}

    # Backup valores originales
    for key in ["JWT_SECRET", "JWT_ALGORITHM", "LOG_LEVEL"]:
        original_env[key] = os.environ.get(key)

    # Configurar valores de test
    os.environ["JWT_SECRET"] = test_constants["jwt_secret"]
    os.environ["JWT_ALGORITHM"] = test_constants["jwt_algorithm"]
    os.environ["LOG_LEVEL"] = "INFO"

    yield

    # Cleanup (siempre se ejecuta)
    for key, value in original_env.items():
        if value is not None:
            os.environ[key] = value
        else:
            os.environ.pop(key, None)


@pytest.fixture(scope="session")
def jwt_secret(test_constants):
    """JWT secret para validaciÃ³n"""
    return test_constants["jwt_secret"]
```

**Archivos donde ELIMINAR `os.environ["JWT_SECRET"] = ...`:**
- `tests/test_mcp/conftest.py:21`
- `tests/test_mcp/test_auth.py:30`
- `tests/test_mcp/test_resources.py:21`
- `tests/test_mcp/test_tools.py:28`

**ValidaciÃ³n:**
```bash
# Tests deben pasar sin os.environ hardcoded
pytest tests/test_mcp/test_auth.py -v
```

---

### 1.4 Eliminar Fixtures Duplicadas

**Archivos a modificar:**
- `tests/test_mcp/conftest.py` (eliminar fixture jwt_secret lÃ­neas 24-27)
- `tests/test_backoffice/test_jwt_validator.py` (eliminar fixture jwt_secret lÃ­neas 14-22)

**Antes:**
```python
# tests/test_mcp/conftest.py:24-27
@pytest.fixture(scope="session")
def jwt_secret():
    """Fixture que proporciona la clave secreta JWT"""
    return "test-secret-key"

# tests/test_backoffice/test_jwt_validator.py:14-22
@pytest.fixture
def jwt_secret():
    """Secret para tests"""
    return "test-secret-key"
```

**DespuÃ©s:**
```python
# ELIMINAR ambas fixtures
# Usar la del conftest.py global
```

**ValidaciÃ³n:**
```bash
grep -r "def jwt_secret" tests/
# Solo debe aparecer en conftest.py (raÃ­z)
```

---

### Checklist Fase 1

- [ ] Modificar `tests/api/conftest.py` (eliminar contenido)
- [ ] Eliminar sys.path de `tests/test_mcp/conftest.py`
- [ ] Eliminar sys.path de `tests/test_mcp/fixtures/tokens.py`
- [ ] Agregar fixtures a `conftest.py` global
- [ ] Eliminar `os.environ["JWT_SECRET"]` de 4 archivos
- [ ] Eliminar fixture jwt_secret duplicada (2 archivos)
- [ ] Ejecutar `pytest tests/api/ -v` â†’ 33 tests deben pasar
- [ ] Ejecutar `./run-tests.sh` â†’ 152/152 tests deben pasar

---

## Fase 2: Refactoring de Fixtures ğŸ”§

**DuraciÃ³n estimada:** 2-3 horas
**Prioridad:** ALTA
**Objetivo:** Eliminar duplicaciÃ³n, mejorar mantenibilidad

### 2.1 Centralizar Constantes de Tests

**Ya implementado en Fase 1.3** âœ…

Todas las constantes ahora vienen de `test_constants` fixture.

---

### 2.2 Mejorar restore_expediente_data con Cleanup

**Archivo a modificar:**
- `tests/test_mcp/conftest.py:58-87`

**Antes:**
```python
@pytest.fixture
def restore_expediente_data():
    # ... restauraciÃ³n ...
    yield

    # Opcionalmente limpiar despuÃ©s del test
    # (por ahora no hacemos nada, dejamos el estado final para debug)
```

**DespuÃ©s:**
```python
@pytest.fixture
def restore_expediente_data():
    """
    Restaura datos de expedientes antes y despuÃ©s de cada test.

    Garantiza idempotencia: ejecutar el mismo test mÃºltiples veces
    produce el mismo resultado.

    Uso:
        @pytest.mark.usefixtures("restore_expediente_data")
        async def test_modificar_datos():
            # Test que modifica datos
            pass
    """
    root_dir = Path(__file__).parent.parent.parent
    data_dir = root_dir / "src" / "mcp_mock" / "mcp_expedientes" / "data" / "expedientes"

    def _restore_from_backup():
        """Helper para restaurar desde archivos .backup"""
        restored_count = 0
        for backup_file in data_dir.glob("*.json.backup"):
            test_file = backup_file.with_suffix("")
            shutil.copy(backup_file, test_file)
            restored_count += 1
        return restored_count

    # Setup: restaurar antes del test
    _restore_from_backup()

    yield

    # Teardown: restaurar despuÃ©s (siempre, incluso si el test falla)
    _restore_from_backup()
```

**ValidaciÃ³n:**
```bash
# Test debe ser idempotente
pytest tests/test_mcp/test_tools.py::test_tool_agregar_documento -v
pytest tests/test_mcp/test_tools.py::test_tool_agregar_documento -v
# Ambas ejecuciones deben pasar
```

---

### 2.3 Eliminar event_loop Fixture Session-Scoped

**Archivo a modificar:**
- `tests/test_backoffice/conftest.py`

**Antes:**
```python
@pytest.fixture(scope="session")
def event_loop():
    """Crea un event loop para toda la sesiÃ³n de tests"""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()
```

**DespuÃ©s:**
```python
# ELIMINAR completamente esta fixture
# pytest-asyncio ya proporciona function-scoped event loops
```

**ValidaciÃ³n:**
```bash
pytest tests/test_backoffice/ -v
# No debe haber warnings sobre event_loop
```

---

### 2.4 Fixtures de Expedientes con Session Scope

**Archivo a modificar:**
- `tests/test_mcp/conftest.py:40-55`

**Antes:**
```python
@pytest.fixture  # function scope por default
def exp_id_subvenciones():
    """ID del expediente de subvenciones"""
    return "EXP-2024-001"
```

**DespuÃ©s:**
```python
@pytest.fixture(scope="session")  # datos inmutables â†’ session scope
def exp_id_subvenciones(test_constants):
    """ID del expediente de subvenciones"""
    return test_constants["default_exp_ids"][0]

@pytest.fixture(scope="session")
def exp_id_licencia(test_constants):
    """ID del expediente de licencia"""
    return test_constants["default_exp_ids"][1]

@pytest.fixture(scope="session")
def exp_id_certificado(test_constants):
    """ID del expediente de certificado"""
    return test_constants["default_exp_ids"][2]
```

**Beneficio:**
- Reduce overhead (fixtures se crean 1 vez en lugar de 100+)
- Datos vienen de constantes centralizadas

---

### Checklist Fase 2

- [ ] Mejorar `restore_expediente_data` con cleanup
- [ ] Eliminar `event_loop` fixture session-scoped
- [ ] Cambiar fixtures de expedientes a session scope
- [ ] Conectar fixtures con `test_constants`
- [ ] Ejecutar `./run-tests.sh` â†’ todos deben pasar
- [ ] Verificar tiempo de ejecuciÃ³n (debe ser similar o menor)

---

## Fase 3: Mejorar Assertions ğŸ¯

**DuraciÃ³n estimada:** 1-2 horas
**Prioridad:** MEDIA
**Objetivo:** Assertions mÃ¡s robustas y especÃ­ficas

### 3.1 Reemplazar `.called` con `assert_called_once()`

**Archivos a modificar:**
- `tests/test_backoffice/test_executor.py` (mÃºltiples lÃ­neas)
- `tests/test_backoffice/test_mcp_integration.py` (mÃºltiples lÃ­neas)

**PatrÃ³n de bÃºsqueda:**
```bash
grep -n "\.called" tests/test_backoffice/test_executor.py
```

**Antes:**
```python
assert mock_jwt_validator.validate.called  # âŒ deprecated
assert mock_logger.log.call_count > 0      # âŒ vago
```

**DespuÃ©s:**
```python
# OpciÃ³n 1: Verificar que se llamÃ³ al menos una vez
mock_jwt_validator.validate.assert_called()

# OpciÃ³n 2: Verificar que se llamÃ³ exactamente una vez
mock_jwt_validator.validate.assert_called_once()

# OpciÃ³n 3: Verificar argumentos especÃ­ficos
mock_jwt_validator.validate.assert_called_once_with(
    token="expected-token",
    secret="test-secret-key",
    algorithm="HS256",
    expected_expediente_id="EXP-2024-001"
)

# Para mÃºltiples llamadas, verificar todas
expected_calls = [
    call(level="INFO", message="Iniciando ejecuciÃ³n"),
    call(level="INFO", message="JWT validado correctamente")
]
mock_logger.log.assert_has_calls(expected_calls, any_order=False)
```

**Script de bÃºsqueda y reemplazo:**
```bash
# Encontrar todos los usos de .called
rg "\.called(?!\()" tests/ -l

# Encontrar call_count > 0
rg "call_count\s*>\s*0" tests/ -l
```

---

### 3.2 Mejorar Assertions en test_protocols.py

**Archivo a modificar:**
- `tests/test_backoffice/test_protocols.py`

**Antes:**
```python
def test_jwt_validator_protocol_structure():
    """Test: JWTValidatorProtocol tiene la firma esperada"""
    assert hasattr(JWTValidatorProtocol, 'validate')
```

**DespuÃ©s:**
```python
import inspect
from typing import get_type_hints

def test_jwt_validator_protocol_structure():
    """Test: JWTValidatorProtocol tiene estructura y signatura correctas"""
    # Verificar que es un Protocol
    assert isinstance(JWTValidatorProtocol, type)

    # Verificar que tiene el mÃ©todo validate
    assert hasattr(JWTValidatorProtocol, 'validate')

    # Verificar que es callable
    validate_method = getattr(JWTValidatorProtocol, 'validate')
    # En Protocols, los mÃ©todos tienen __annotations__
    assert hasattr(validate_method, '__annotations__'), \
        "validate() debe tener type annotations"

    # Verificar parÃ¡metros esperados
    annotations = validate_method.__annotations__
    # Debe tener al menos 'token' y 'return'
    assert len(annotations) > 0, "validate() debe estar anotado"
```

Aplicar patrÃ³n similar a:
- `test_mcp_client_protocol_structure()`
- `test_audit_logger_protocol_structure()`
- Todos los tests de protocols

---

### 3.3 Agregar VerificaciÃ³n de Args en Mocks CrÃ­ticos

**Archivos a modificar:**
- `tests/test_backoffice/test_executor.py`

**Tests a mejorar:**

```python
def test_tc_ex_001_ejecucion_exitosa(executor, mock_jwt_validator, ...):
    """Test: EjecuciÃ³n exitosa completa del AgentExecutor"""
    # ... setup ...

    result = await executor.execute(
        agent_config=agent_config,
        jwt_token="valid-token",
        expediente_id="EXP-2024-001",
        task_description="DescripciÃ³n tarea"
    )

    # MEJORAR: Verificar argumentos especÃ­ficos
    mock_jwt_validator.validate.assert_called_once_with(
        token="valid-token",
        secret=settings.jwt_secret,
        algorithm=settings.jwt_algorithm,
        expected_expediente_id="EXP-2024-001"
    )

    # Verificar que registry se creÃ³ con config correcto
    mock_registry_class.assert_called_once()
    call_args = mock_registry_class.call_args
    assert call_args[0][0] == settings.mcp_config_path
    assert call_args[1]['jwt_token'] == "valid-token"
```

---

### Checklist Fase 3

- [ ] Buscar y reemplazar `.called` â†’ `assert_called_once()`
- [ ] Mejorar assertions en `test_protocols.py` (7 tests)
- [ ] Agregar verificaciÃ³n de args en mocks de `test_executor.py`
- [ ] Ejecutar tests afectados individualmente
- [ ] Verificar que assertions mÃ¡s especÃ­ficas atrapan bugs

---

## Fase 4: Cleanup y DocumentaciÃ³n ğŸ“

**DuraciÃ³n estimada:** 1 hora
**Prioridad:** BAJA
**Objetivo:** CÃ³digo mÃ¡s limpio y mejor documentado

### 4.1 Re-enable Test Skipped con Issue Tracker

**Archivo a modificar:**
- `tests/test_mcp/test_server_http.py:116`

**Antes:**
```python
def test_sse_endpoint_token_valido_permite_procesamiento():
    """..."""
    pytest.skip("Test deshabilitado: transporte SSE causa timeouts en tests unitarios")
```

**DespuÃ©s:**
```python
@pytest.mark.skip(reason="SSE transport causes timeouts in unit tests - Issue #TODO")
def test_sse_endpoint_token_valido_permite_procesamiento():
    """
    Test de endpoint SSE con token vÃ¡lido.

    DISABLED: El transporte SSE en tests unitarios causa timeouts.
    Ver issue GitHub #TODO para tracking.

    Posibles soluciones:
    - Mock del EventSourceResponse
    - Usar pytest-timeout
    - Refactor a test de integraciÃ³n con timeout mayor
    """
    # TODO: Implementar cuando se resuelva issue
```

**AcciÃ³n adicional:**
- Crear issue en GitHub describiendo el problema
- Actualizar `#TODO` con nÃºmero de issue real

---

### 4.2 Estandarizar Nombres de Fixtures

**Archivos a modificar:**
- `tests/test_mcp/conftest.py`

**Antes (mezcla espaÃ±ol/inglÃ©s):**
```python
test_expedientes()      # espaÃ±ol
jwt_secret()           # inglÃ©s
exp_id_subvenciones()  # espaÃ±ol abreviado
```

**DespuÃ©s (inglÃ©s consistente):**
```python
test_expediente_ids()      # inglÃ©s
jwt_secret()              # inglÃ©s
subvenciones_exp_id()     # inglÃ©s (mÃ¡s natural)
# o mantener exp_id_* si es el estÃ¡ndar del equipo
```

**DecisiÃ³n de equipo:** Â¿InglÃ©s o espaÃ±ol?
- Si cÃ³digo estÃ¡ en espaÃ±ol â†’ fixtures en espaÃ±ol
- Si cÃ³digo mixto â†’ usar inglÃ©s (estÃ¡ndar Python)

---

### 4.3 Mejorar Docstrings Redundantes

**PatrÃ³n a buscar:**
```bash
grep -A 2 "def test_" tests/ | grep '"""Test:'
```

**Antes:**
```python
def test_jwt_expired_returns_auth_error(...):
    """Test: Token expirado retorna error AUTH_TOKEN_EXPIRED"""
    # Setup
    # Execute
    # Assert
```

**DespuÃ©s:**
```python
def test_jwt_expired_returns_auth_error(...):
    """
    Verifica rechazo de tokens JWT expirados.

    El AgentExecutor debe detectar tokens expirados durante validaciÃ³n
    JWT y retornar AgentExecutionResult con:
    - success=False
    - error.codigo="AUTH_TOKEN_EXPIRED"
    - Sin intentar crear MCP registry

    Esto previene uso de credenciales expiradas en llamadas a MCPs.
    """
```

Eliminar comentarios vacÃ­os:
- `# Setup`
- `# Execute`
- `# Assert`

(Solo Ãºtiles en tests complejos donde cada secciÃ³n tiene 10+ lÃ­neas)

---

### 4.4 Crear pytest.ini

**Archivo a crear:**
- `pytest.ini` (raÃ­z del proyecto)

```ini
[pytest]
# Directorio de tests
testpaths = tests

# PatrÃ³n de archivos de test
python_files = test_*.py

# PatrÃ³n de clases de test
python_classes = Test*

# PatrÃ³n de funciones de test
python_functions = test_*

# Opciones por defecto
addopts =
    # Output verboso
    -v
    # Mostrar resumen de tests
    -ra
    # Mostrar warnings
    --strict-markers
    # Asyncio mode
    --asyncio-mode=auto

# Markers personalizados
markers =
    slow: tests lentos (>1s)
    integration: tests de integraciÃ³n
    unit: tests unitarios

# Asyncio configuration
asyncio_mode = auto

# Warnings
filterwarnings =
    # Convertir PydanticDeprecatedSince20 en errores (forzar fix)
    error::pydantic.warnings.PydanticDeprecatedSince20
    # Ignorar warnings de dependencias externas
    ignore::DeprecationWarning:starlette.*
```

**Uso:**
```bash
# Tests rÃ¡pidos solamente
pytest -m "not slow"

# Solo tests unitarios
pytest -m unit

# Ver markers disponibles
pytest --markers
```

---

### 4.5 Eliminar Imports Redundantes

**Script de bÃºsqueda:**
```bash
# Encontrar imports no usados
ruff check tests/ --select F401
# o
flake8 tests/ --select=F401
```

**Ejemplos comunes:**
```python
# Si httpx solo se usa en mocks
import httpx  # âŒ Redundante

# Usar lazy import o eliminar
from unittest.mock import AsyncMock
# ... en test:
mock_response = AsyncMock(spec=httpx.Response)  # No requiere import
```

---

### Checklist Fase 4

- [ ] Crear issue para test skipped SSE
- [ ] Actualizar skip marker con issue number
- [ ] Decidir estÃ¡ndar de nombres (inglÃ©s/espaÃ±ol)
- [ ] Renombrar fixtures segÃºn estÃ¡ndar
- [ ] Mejorar docstrings redundantes (10-20 tests)
- [ ] Crear `pytest.ini` con configuraciÃ³n
- [ ] Eliminar imports no usados
- [ ] Ejecutar `pytest --markers` para validar

---

## Fase 5: MÃ©tricas y CI/CD ğŸ“Š

**DuraciÃ³n estimada:** 2-3 horas
**Prioridad:** OPCIONAL
**Objetivo:** Visibility sobre calidad y cobertura

### 5.1 Configurar Coverage.py

**Instalar:**
```bash
pip install pytest-cov
```

**Crear `.coveragerc`:**
```ini
[run]
source = src/
omit =
    */tests/*
    */conftest.py
    */__pycache__/*
    */venv/*

[report]
precision = 2
show_missing = True
skip_covered = False

exclude_lines =
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:
    if TYPE_CHECKING:
    @abstractmethod

[html]
directory = htmlcov
```

**Actualizar pytest.ini:**
```ini
addopts =
    ...
    # Coverage
    --cov=src
    --cov-report=term-missing
    --cov-report=html
    --cov-fail-under=80
```

**Ejecutar:**
```bash
pytest --cov
# Ver reporte HTML
open htmlcov/index.html
```

---

### 5.2 Pre-commit Hook

**Crear `.pre-commit-config.yaml`:**
```yaml
repos:
  - repo: local
    hooks:
      - id: pytest-quick
        name: Run fast tests
        entry: pytest
        args: ["-m", "not slow", "--tb=short"]
        language: system
        pass_filenames: false
        always_run: true
```

**Instalar:**
```bash
pip install pre-commit
pre-commit install
```

**Uso:**
```bash
# Se ejecuta automÃ¡ticamente en git commit
git commit -m "mensaje"
# Tests rÃ¡pidos se ejecutan antes de permitir commit
```

---

### 5.3 GitHub Actions CI

**Crear `.github/workflows/tests.yml`:**
```yaml
name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        pip install -e .
        pip install pytest pytest-asyncio pytest-cov

    - name: Run tests with coverage
      run: |
        pytest --cov=src --cov-report=xml --cov-fail-under=80

    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
```

---

### 5.4 Coverage Badge

**Agregar a README.md:**
```markdown
[![Coverage](https://codecov.io/gh/USUARIO/aGEntiX/branch/main/graph/badge.svg)](https://codecov.io/gh/USUARIO/aGEntiX)
[![Tests](https://github.com/USUARIO/aGEntiX/workflows/Tests/badge.svg)](https://github.com/USUARIO/aGEntiX/actions)
```

---

### Checklist Fase 5

- [ ] Instalar pytest-cov
- [ ] Crear `.coveragerc`
- [ ] Actualizar pytest.ini con coverage
- [ ] Ejecutar y verificar coverage > 80%
- [ ] Crear `.pre-commit-config.yaml`
- [ ] Instalar pre-commit hooks
- [ ] Crear GitHub Actions workflow
- [ ] Configurar Codecov
- [ ] Agregar badges a README

---

## Resumen de Archivos Modificados

### Crear
- [ ] `pytest.ini`
- [ ] `.coveragerc` (Fase 5)
- [ ] `.pre-commit-config.yaml` (Fase 5)
- [ ] `.github/workflows/tests.yml` (Fase 5)

### Modificar
- [ ] `conftest.py` (agregar fixtures)
- [ ] `tests/api/conftest.py` (simplificar)
- [ ] `tests/test_mcp/conftest.py` (eliminar duplicaciÃ³n)
- [ ] `tests/test_mcp/fixtures/tokens.py` (eliminar sys.path)
- [ ] `tests/test_backoffice/conftest.py` (eliminar event_loop)
- [ ] `tests/test_backoffice/test_executor.py` (assertions)
- [ ] `tests/test_backoffice/test_protocols.py` (assertions)
- [ ] `tests/test_mcp/test_*.py` (eliminar os.environ)

### Eliminar cÃ³digo de
- [ ] 4 archivos con `os.environ["JWT_SECRET"]`
- [ ] 3 archivos con manipulaciÃ³n de sys.path
- [ ] 2 archivos con fixture jwt_secret duplicada
- [ ] 1 archivo con event_loop session-scoped

---

## EstimaciÃ³n de Esfuerzo

| Fase | DuraciÃ³n | Prioridad | ROI |
|------|----------|-----------|-----|
| Fase 1 | 1-2h | CRÃTICA | ğŸ”´ Alto - Fix 33 tests rotos |
| Fase 2 | 2-3h | ALTA | ğŸŸ  Alto - Elimina duplicaciÃ³n |
| Fase 3 | 1-2h | MEDIA | ğŸŸ¡ Medio - Mejora robustez |
| Fase 4 | 1h | BAJA | ğŸŸ¢ Bajo - Limpieza |
| Fase 5 | 2-3h | OPCIONAL | ğŸ”µ Variable - SegÃºn needs |

**Total (Fases 1-4):** 5-8 horas
**Total (con Fase 5):** 7-11 horas

---

## Criterios de Ã‰xito

### DespuÃ©s de Fase 1
- âœ… 152/152 tests ejecutÃ¡ndose (100%)
- âœ… 0 warnings de sys.path
- âœ… 1 solo lugar con manipulaciÃ³n de sys.path

### DespuÃ©s de Fase 2
- âœ… 0 fixtures duplicadas
- âœ… restore_expediente_data idempotente
- âœ… 0 session-scoped event_loop fixtures

### DespuÃ©s de Fase 3
- âœ… 0 usos de `.called` (deprecated)
- âœ… Assertions especÃ­ficas en mocks crÃ­ticos
- âœ… test_protocols.py con verificaciones robustas

### DespuÃ©s de Fase 4
- âœ… pytest.ini configurado
- âœ… Docstrings mejorados
- âœ… Issue tracker para test skipped

### DespuÃ©s de Fase 5
- âœ… Coverage > 80%
- âœ… CI/CD ejecutando tests
- âœ… Badges de coverage en README

---

## Siguiente Paso

**Â¿Implementar Fase 1 ahora?**

Puedo implementar los arreglos crÃ­ticos de Fase 1 inmediatamente para hacer que los 33 tests de API se ejecuten.

```bash
# Comando para validar despuÃ©s de implementar
pytest tests/api/ -v
./run-tests.sh
# Debe mostrar: 152 tests PASSED
```
